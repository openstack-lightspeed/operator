##############################################################################
#        Mock API tokens and certificates required for OLSConfig tests       #
##############################################################################
---
apiVersion: v1
kind: Secret
type: Opaque
metadata:
  name: openstack-lightspeed-apitoken
  namespace: openshift-lightspeed
stringData:
  apitoken: secret
---
apiVersion: v1
kind: ConfigMap
type: Opaque
metadata:
  name: openstack-lightspeed-cert
  namespace: openshift-lightspeed
data:
  cert: |
    -----BEGIN CERTIFICATE-----
    MIIEMDCCAxigAwIBAgIJANqb7HHzA7AZMA0GCSqGSIb3DQEBCwUAMIGkMQswCQYD
    VQQGEwJQQTEPMA0GA1UECAwGUGFuYW1hMRQwEgYDVQQHDAtQYW5hbWEgQ2l0eTEk
    MCIGA1UECgwbVHJ1c3RDb3IgU3lzdGVtcyBTLiBkZSBSLkwuMScwJQYDVQQLDB5U
    cnVzdENvciBDZXJ0aWZpY2F0ZSBBdXRob3JpdHkxHzAdBgNVBAMMFlRydXN0Q29y
    IFJvb3RDZXJ0IENBLTEwHhcNMTYwMjA0MTIzMjE2WhcNMjkxMjMxMTcyMzE2WjCB
    pDELMAkGA1UEBhMCUEExDzANBgNVBAgMBlBhbmFtYTEUMBIGA1UEBwwLUGFuYW1h
    IENpdHkxJDAiBgNVBAoMG1RydXN0Q29yIFN5c3RlbXMgUy4gZGUgUi5MLjEnMCUG
    A1UECwweVHJ1c3RDb3IgQ2VydGlmaWNhdGUgQXV0aG9yaXR5MR8wHQYDVQQDDBZU
    cnVzdENvciBSb290Q2VydCBDQS0xMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIB
    CgKCAQEAv463leLCJhJrMxnHQFgKq1mqjQCj/IDHUHuO1CAmujIS2CNUSSUQIpid
    RtLByZ5OGy4sDjjzGiVoHKZaBeYei0i/mJZ0PmnK6bV4pQa81QBeCQryJ3pS/C3V
    seq0iWEk8xoT26nPUu0MJLq5nux+AHT6k61sKZKuUbS701e/s/OojZz0JEsq1pme
    9J7+wH5COucLlVPat2gOkEz7cD+PSiyU8ybdY2mplNgQTsVHCJCZGxdNuWxu72CV
    EY4hgLW9oHPY0LJ3xEXqWib7ZnZ2+AYfYW0PVcWDtxBWcgYHpfOxGgMFZA6dWorW
    hnAbJN7+KIor0Gqw/Hqi3LJ5DotlDwIDAQABo2MwYTAdBgNVHQ4EFgQU7mtJPHo/
    DeOxCbeKyKsZn3MzUOcwHwYDVR0jBBgwFoAU7mtJPHo/DeOxCbeKyKsZn3MzUOcw
    DwYDVR0TAQH/BAUwAwEB/zAOBgNVHQ8BAf8EBAMCAYYwDQYJKoZIhvcNAQELBQAD
    ggEBACUY1JGPE+6PHh0RU9otRCkZoB5rMZ5NDp6tPVxBb5UrJKF5mDo4Nvu7Zp5I
    /5CQ7z3UuJu0h3U/IJvOcs+hVcFNZKIZBqEHMwwLKeXx6quj7LUKdJDHfXLy11yf
    ke+Ri7fc7Waiz45mO7yfOgLgJ90WmMCV1Aqk5IGadZQ1nJBfiDcGrVmVCrDRZ9MZ
    yonnMlo2HD6CqFqTvsbQZJG2z9m2GM/bftJlo6bEjhcxwft+dtvTheNYsnd6djts
    L1Ac59v2Z3kf9YKVmgenFK+P3CghZwnS1k1aHBkcjndcw5QkPTJrS37UeJSDvjdN
    zl/HHk484IkzlQsPpTLWPFp5LBk=
    -----END CERTIFICATE-----

##############################################################################
#         Mock Pod to simulate OpenAI /chat/completions API endpoints        #
#         Used by OpenShiftLightspeed for LLM connection verification        #
##############################################################################
---
apiVersion: v1
kind: Pod
metadata:
  name: mock-llm-api-server-pod
  labels:
    app: mock-llm-api-server-pod
spec:
  containers:
    - name: mock-llm-api-server
      image: registry.redhat.io/ubi8/python-311:latest
      ports:
        - containerPort: 8000
      volumeMounts:
        - name: app-code
          mountPath: /app
      workingDir: /app
      command:
        - sh
        - -c
        - |
          pip install "fastapi[standard]" && \
          uvicorn app:app --host 0.0.0.0 --port 8000
  volumes:
    - name: app-code
      configMap:
        name: mock-llm-code
---
apiVersion: v1
kind: Service
metadata:
  name: mock-llm-api-server-pod
spec:
  selector:
    app: mock-llm-api-server-pod
  ports:
    - protocol: TCP
      port: 8000
      targetPort: 8000
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: mock-llm-code
data:
  app.py: |
    from fastapi import FastAPI, Request
    from fastapi.responses import JSONResponse

    app = FastAPI()
    @app.post("/v1/chat/completions")
    async def completions_post(request: Request):
        try:
            body = await request.json()
        except Exception:
            body = {}

        # Always return a valid OpenAI-like response, handle missing/None body gracefully
        model = body.get("model", "gpt-3.5-turbo") if isinstance(body, dict) else "gpt-3.5-turbo"

        # The OpenAI API expects 'messages' (for chat) or 'prompt' (for completions), but for mock, we will accept either
        response = {
            "id": "cmpl-123",
            "object": "chat.completion",
            "created": 1234567890,
            "model": model,
            "choices": [
                {
                    "index": 0,
                    "message": {
                        "role": "assistant",
                        "content": "Hello, this is a dummy chat completion."
                    },
                    "finish_reason": "stop"
                }
            ],
            "usage": {
                "prompt_tokens": 5,
                "completion_tokens": 7,
                "total_tokens": 12
            }
        }
        return JSONResponse(content=response)

