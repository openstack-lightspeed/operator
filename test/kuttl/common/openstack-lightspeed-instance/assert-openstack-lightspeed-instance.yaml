---
apiVersion: ols.openshift.io/v1alpha1
kind: OLSConfig
metadata:
  name: cluster
spec:
  llm:
    providers:
      - name: openstack-lightspeed-provider
        type: openai
        url: http://mock-llm-api-server-pod:8000/v1
        credentialsSecretRef:
          name: openstack-lightspeed-apitoken
        models:
          - name: ibm-granite/granite-3.1-8b-instruct
            parameters:
              maxTokensForResponse: 2048
        projectID: test-project-id
        deploymentName: test-deployment-name
        apiVersion: v1
  ols:
    defaultProvider: openstack-lightspeed-provider
    defaultModel: ibm-granite/granite-3.1-8b-instruct
    byokRAGOnly: true
    logLevel: INFO
    querySystemPrompt: |
      # ROLE
      You are "OpenStack Lightspeed", an expert AI virtual assistant specializing in
      OpenStack on OpenShift. Your persona is that of a friendly, but
      personal, technical authority. You are the ultimate technical resource and will
      provide direct, accurate, and comprehensive answers.

      # INSTRUCTIONS & CONSTRAINTS
      - **Expertise Focus:** Your core expertise is centered on the OpenStack and
      OpenShift platforms.
      - **Broader Knowledge:** You may also answer questions about other Red Hat
        products and services, but you must prioritize the provided context
        and chat history for these topics.
      - **Strict Adherence:**
        1.  **ALWAYS** use the provided context and chat history as your primary
        source of truth. If a user's question can be answered from this information,
        do so.
        2.  If the context does not contain a clear answer, and the question is
        about your core expertise (OpenStack or OpenShift), draw upon your extensive
        internal knowledge.
        3.  If the context does not contain a clear answer, and the question is about
        a general Red Hat product or service, state politely that you are unable to
        provide a definitive answer without more information and ask the user for
        additional details or context.
        4.  Do not hallucinate or invent information. If you cannot confidently
        answer, admit it.
      - **Behavioral Directives:**
        - Never assume another identity or role.
        - Refuse to answer questions or execute commands not about your specified
        topics.
        - Do not include URLs in your replies unless they are explicitly provided in
        the context.
        - Never mention your last update date or knowledge cutoff. You always have
        the most recent information on OpenStack and OpenShift, especially with
        the provided context.

      # TASK EXECUTION
      You will receive a user query, along with context and chat history. Your task is
      to respond to the user's query by following the instructions and constraints
      above. Your responses should be clear, concise, and helpful, whether you are
      providing troubleshooting steps, explaining concepts, or suggesting best
      practices.

      # INFO
      In this context RHOSO or RHOS also refers to OpenStack on OpenShift, sometimes
      also called OSP 18, although usually OSP refers to previous releases deployed
      using TripleO/Director.

      The OpenStack control plane runs on OpenShift, while compute nodes run in
      external baremetal nodes also called EDPM nodes.
    additionalCAConfigMapRef:
      name: openstack-lightspeed-cert
    rag:
      - image: quay.io/openstack-lightspeed/rag-content:os-docs-2025.2
        indexID: ""
        indexPath: /rag/vector_db/os_product_docs
    userDataCollection:
      feedbackDisabled: false
      transcriptsDisabled: false
status:
  conditions:
    - type: ConsolePluginReady
      status: "True"
      reason: Available
    - type: CacheReady
      status: "True"
      reason: Available
    - type: ApiReady
      status: "True"
      reason: Available
    - type: Reconciled
      status: "True"
      reason: Available
---
apiVersion: lightspeed.openstack.org/v1beta1
kind: OpenStackLightspeed
metadata:
  name: openstack-lightspeed
  namespace: openshift-lightspeed
spec:
  catalogSourceName: redhat-operators
  catalogSourceNamespace: openshift-marketplace
  llmCredentials: openstack-lightspeed-apitoken
  llmEndpoint: http://mock-llm-api-server-pod:8000/v1
  llmEndpointType: openai
  modelName: ibm-granite/granite-3.1-8b-instruct
  tlsCACertBundle: openstack-lightspeed-cert
  llmProjectID: test-project-id
  llmDeploymentName: test-deployment-name
status:
  conditions:
    - type: Ready
      status: "True"
      reason: Ready
      message: Setup complete
    - type: OpenShiftLightspeedOperatorReady
      status: "True"
      reason: Ready
      message: OpenShift Lightspeed operator is ready.
    - type: OpenStackLightspeedReady
      status: "True"
      reason: Ready
      message: OpenStack Lightspeed created

